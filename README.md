# Real-Time News Retrieval-Augmented Generation (RAG) System

## ğŸ“Œ Project Overview

This project implements a **Real-Time News Retrieval-Augmented Generation (RAG) pipeline** that ingests live news articles, converts them into dense vector embeddings, and enables **semantic search** over the latest news using **FAISS**.

Instead of keyword-based search, the system retrieves news articles based on **semantic similarity**, ensuring more relevant and context-aware results.

The project focuses on:
- Real-time data ingestion
- Efficient document storage
- Vector-based semantic retrieval
- Practical, submission-ready architecture

---

## ğŸ§  Key Features

- ğŸ”„ Live news ingestion using NewsAPI
- ğŸ§¹ Deduplication of articles using URL hashing
- ğŸ“„ Persistent document storage (JSONL format)
- ğŸ”¢ Dense embeddings using SentenceTransformers
- âš¡ Fast similarity search using FAISS
- ğŸ’» CLI-based querying interface

---

## ğŸ—ï¸ Project Architecture

NewsAPI
â†“
Ingestion (news_writer.py)
â†“
JSONL Document Store
â†“
SentenceTransformer Embeddings
â†“
FAISS Vector Index
â†“
Semantic Retrieval (Top-K)
â†“
CLI Output

---

## ğŸ“ Project Structure

data_quest/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ ingestion/
â”‚ â”‚ â””â”€â”€ news_writer.py # Fetches and stores live news
â”‚ â”‚
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â””â”€â”€ news.jsonl # Stored news articles (JSON Lines)
â”‚ â”‚
â”‚ â””â”€â”€ config.py # Environment & path configuration
â”‚
â”œâ”€â”€ test_faiss.py # FAISS indexing + query interface
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env # API keys (not committed)
â””â”€â”€ README.md


---

## âš™ï¸ Prerequisites

- Python **3.10 or 3.11**
- NewsAPI API key  
  (https://newsapi.org/)
- OS: Linux / macOS / Windows (WSL recommended)

---

## ğŸ” Environment Setup

### 1ï¸âƒ£ Clone the repository
```bash
git clone <your-repo-url>
cd data_quest
```
Create & activate virtual environment
```bash
python -m venv pathway-env
source pathway-env/bin/activate
```
Install dependencies
```
pip install -r requirements.txt
```
Environment Variables

Create a .env file in the project root:
```
NEWS_API_KEY=your_newsapi_key_here
```
Step 1: Run News Ingestion
This script continuously fetches live news and stores them locally.
```
python backend/ingestion/news_writer.py
```
What this does:


Fetches latest news from NewsAPI


Deduplicates articles


Appends articles to backend/data/news.jsonl


Stop anytime using:
CTRL + C


ğŸ” Step 2: Run FAISS Semantic Search
Once news is collected, run:
```
python test_faiss.py
```
You will see:
[FAISS] Loaded XX documents
[FAISS] Indexed XX documents
Enter query:

Example Queries
africa vaccine
technology startup
global trade agreement
sports tournament

The system returns Top-K semantically relevant articles.

âœ… What Is Completed
âœ” Real-time ingestion
âœ” Persistent storage
âœ” Dense embeddings
âœ” FAISS indexing
âœ” Semantic search
âœ” CLI-based querying

âŒ What Is Intentionally Excluded


Frontend UI (CLI used instead)


LLM answer generation (retrieval-focused RAG)


Metadata filtering (future enhancement)



ğŸš€ Future Enhancements


LLM-based answer generation


Web UI (Streamlit / FastAPI)


Metadata filters (date, category)


Deployment as an API service



ğŸ“Š Sample Output
Query: africa vaccine

Top results:
- RFK-backed infant vaccine study in Africa â€“ Washington Post
- Related international health policy news
- Additional contextually relevant articles


ğŸ§ª Evaluation Notes


Uses industry-grade FAISS indexing


Designed for real-time updates


Scales efficiently with growing data


Submission-aligned, reproducible pipeline



Made for IIT KGP DATA quest 

ğŸ“„ License
This project is for academic and educational use.

---

